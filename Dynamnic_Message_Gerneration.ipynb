{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrc4EsuyrTvXv2emmXvID9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Suriyanand/GEN_AI_PROJECTS/blob/main/Dynamnic_Message_Gerneration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuYkxSBVRbIw"
      },
      "outputs": [],
      "source": [
        "\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "import os\n",
        "GOOGLE_API_KEY=userdata.get('GOOGLE_API_KEY')\n",
        "genai.configure(api_key=GOOGLE_API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = genai.GenerativeModel(model_name = \"models/gemini-1.5-flash\")\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m16-0QDATFSb",
        "outputId": "acbe4c23-2b73-45a7-d37d-b466fdeb311f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "genai.GenerativeModel(\n",
              "    model_name='models/gemini-1.5-flash',\n",
              "    generation_config={},\n",
              "    safety_settings={},\n",
              "    tools=None,\n",
              "    system_instruction=None,\n",
              "    cached_content=None\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response = model.generate_content(\"What are the usecases of LLMs?\")\n",
        "print(response.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 766
        },
        "id": "ej51M6fpTGxS",
        "outputId": "c89d7e03-1229-4bf8-c05b-d8286d0963a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Large Language Models (LLMs) have a rapidly expanding range of use cases, impacting many industries and aspects of daily life.  Here are some key areas:\n",
            "\n",
            "**Content Creation & Enhancement:**\n",
            "\n",
            "* **Text generation:** Writing articles, summaries, poems, code, scripts, emails, marketing copy, etc.\n",
            "* **Translation:** Accurate and nuanced translation between multiple languages.\n",
            "* **Paraphrasing and rewriting:** Improving clarity, tone, and style of existing text.\n",
            "* **Chatbots and conversational AI:** Providing interactive and engaging customer service, virtual assistants, and educational tools.\n",
            "* **Content summarization:** Condensing large amounts of text into concise summaries.\n",
            "\n",
            "**Data Analysis & Insights:**\n",
            "\n",
            "* **Sentiment analysis:** Determining the emotional tone of text data (e.g., social media posts, customer reviews).\n",
            "* **Topic extraction:** Identifying key themes and topics within large datasets.\n",
            "* **Question answering:** Providing accurate and informative answers to complex questions based on given context.\n",
            "* **Data labeling and annotation:** Assisting in the process of preparing data for machine learning models.\n",
            "\n",
            "**Software Development:**\n",
            "\n",
            "* **Code generation:** Assisting programmers in writing and debugging code.\n",
            "* **Code completion:** Suggesting code completions as programmers type.\n",
            "* **Code documentation:** Automatically generating documentation for codebases.\n",
            "* **Bug detection:** Identifying potential bugs and vulnerabilities in code.\n",
            "\n",
            "**Education & Research:**\n",
            "\n",
            "* **Personalized learning:** Tailoring educational content to individual student needs.\n",
            "* **Automated essay grading:** Providing quick and efficient feedback on student writing.\n",
            "* **Research assistance:** Summarizing research papers, identifying relevant literature, and generating hypotheses.\n",
            "\n",
            "**Other Applications:**\n",
            "\n",
            "* **Healthcare:** Analyzing medical records, generating patient reports, and assisting with diagnosis.\n",
            "* **Finance:** Analyzing financial data, detecting fraud, and providing personalized financial advice.\n",
            "* **Legal:** Summarizing legal documents, assisting with legal research, and drafting legal documents.\n",
            "* **Customer service:** Providing 24/7 customer support through chatbots and virtual assistants.\n",
            "* **Accessibility:** Assisting individuals with disabilities through text-to-speech and speech-to-text capabilities.\n",
            "* **Creative arts:** Generating novel creative content like music, scripts and stories.\n",
            "\n",
            "\n",
            "It's important to note that while LLMs offer immense potential, they also have limitations.  They can sometimes generate inaccurate, biased, or nonsensical outputs.  Ethical considerations and responsible development are crucial for ensuring their beneficial use.  The applications continue to evolve rapidly as research progresses and the capabilities of LLMs improve.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q google-generativeai\n"
      ],
      "metadata": {
        "id": "HU0ZgZ9TTL6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3RDhswuQTian"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}